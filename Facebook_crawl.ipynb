{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_id = ''\n",
    "facebook_psw = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import facebook\n",
    "import urllib3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException,NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url):\n",
    "    time.sleep(0.4)\n",
    "    response=requests.get(url=url)\n",
    "    if response.status_code != 200:  #回傳200代表正常\n",
    "        print('Invalid url:', response.url)\n",
    "        return None\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs4soup(driver):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webdriver_crawl(driver, xpath):\n",
    "    try:\n",
    "        content = driver.find_element_by_xpath(xpath).text\n",
    "        return content\n",
    "    except NoSuchElementException:\n",
    "        return \"?\"\n",
    "    time.sleep(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_country(soup):\n",
    "    p_tags = soup.findAll('div', class_ ='clearfix _h71')\n",
    "    current = \"?\"\n",
    "    hometown = \"?\"\n",
    "    for p_tag in p_tags:\n",
    "        contents = p_tag.findNext('ul', class_ = 'uiList fbProfileEditExperiences _4kg _4ks')\n",
    "        for content in contents:\n",
    "            try:\n",
    "                prefix = content.find('div', class_ = 'fsm fwn fcg').text\n",
    "                if prefix == '現居城市':\n",
    "                    current = content.find('span', class_ = '_2iel _50f7').text\n",
    "                elif prefix == '家鄉':\n",
    "                    hometown = content.find('span', class_ = '_2iel _50f7').text\n",
    "            except:\n",
    "                pass\n",
    "    return current, hometown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_work_education(soup):\n",
    "    p_tags = soup.findAll('div', class_ ='clearfix _h71')\n",
    "    work = []\n",
    "    education = []\n",
    "    for p_tag in p_tags:\n",
    "        contents = p_tag.findNext('ul', class_ = 'uiList fbProfileEditExperiences _4kg _4ks')\n",
    "        for content in contents:\n",
    "            if p_tag.text == '工作經歷':\n",
    "                try:\n",
    "                    work.append(content.find('div', class_ = '_2lzr _50f5 _50f7').text)\n",
    "                except:\n",
    "                    pass\n",
    "            elif p_tag.text == '學歷':\n",
    "                try:\n",
    "                    education.append(content.find('div', class_ = '_2lzr _50f5 _50f7').text)\n",
    "                except:\n",
    "                    pass\n",
    "    if work == []:\n",
    "        work = \"?\"\n",
    "    if education == []:\n",
    "        education = \"?\"\n",
    "    return work, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_star(birthday):\n",
    "    age = '?'\n",
    "    star_sign = '?'\n",
    "    if birthday == '?':\n",
    "        return age, star_sign\n",
    "    if '年' in birthday:\n",
    "        year = int(birthday.split('年')[0])\n",
    "        month = int(birthday.split('年')[1].split('月')[0])\n",
    "        date = int(birthday.split('年')[1].split('月')[1].split('日')[0])\n",
    "        age = 2018 - year\n",
    "        star_sign = \"?\"\n",
    "        return age, star_sign\n",
    "    else:\n",
    "        month = int(birthday.split('月')[0])\n",
    "        date = int(birthday.split('月')[1].split('日')[0])\n",
    "        star_sign = \"?\"\n",
    "        return age, star_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_relationship(soup):\n",
    "    p_tags = soup.findAll('div', class_ ='clearfix _h71')\n",
    "    relationship = '?'\n",
    "    for p_tag in p_tags:\n",
    "        contents = p_tag.findNext('ul', class_ = 'uiList fbProfileEditExperiences _4kg _4ks')\n",
    "        for content in contents:\n",
    "            if p_tag.text == '感情狀況':\n",
    "                relationship = content.text\n",
    "    if relationship == '沒有感情狀況資訊可顯示':\n",
    "        relationship = '無'\n",
    "    return relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_basic_info(soup):\n",
    "    p_tags = soup.findAll('div', class_ ='clearfix _h71')\n",
    "    birthday = '?'\n",
    "    gender = '?'\n",
    "    blood = '?'\n",
    "    sex_orientation = '?'\n",
    "    language = '?'\n",
    "    religion = '?'\n",
    "\n",
    "    for p_tag in p_tags:\n",
    "        #contents = p_tag.findNext('ul', class_ = 'uiList fbProfileEditExperiences _4kg _4ks')\n",
    "        if p_tag.text == '基本資料':\n",
    "            contents = p_tag.findAllNext('div', class_ = '_4bl7 _3xdi _52ju')\n",
    "            for content in contents:\n",
    "                if content.text == '生日':\n",
    "                    birthday = content.findNext('div', class_ = '_4bl7 _pt5').text\n",
    "                elif content.text == '性別':\n",
    "                    gender = content.findNext('div', class_ = '_4bl7 _pt5').text\n",
    "                elif content.text == '血型':\n",
    "                    blood = content.findNext('div', class_ = '_4bl7 _pt5').text\n",
    "                elif content.text == '戀愛性向':\n",
    "                    sex_orientation = content.findNext('div', class_ = '_4bl7 _pt5').text\n",
    "                elif content.text == '語言':\n",
    "                    language = content.findNext('div', class_ = '_4bl7 _pt5').text\n",
    "                elif content.text == '宗教信仰':\n",
    "                    religion = content.findNext('div', class_ = '_4bl7 _pt5').text\n",
    "    return birthday, gender, blood, sex_orientation, language, religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_information(driver,profile_url):\n",
    "    all_result=[]\n",
    "    \"\"\"\n",
    "    中文姓名、英文姓名、FB帳號、ig帳號、居住地區、來自地區、地址、工作、學歷(畢業國中、高中、大學、研究所)、性別、血型、性向、語言、宗教、生日、年齡、星座、gmail、手機號碼、父母名字、感情狀態\n",
    "    \"\"\"\n",
    "    \n",
    "    #========== 中文姓名 ==========\n",
    "    xpath = \"/html/body/div[1]/div[3]/div[1]/div/div[2]/div[2]/div[1]/div/div[1]/div/div[3]/div/div[1]/div/div/h1/span[1]/a\"\n",
    "    all_result.append(webdriver_crawl(driver, xpath))\n",
    "\n",
    "    #========== 英文姓名 ==========\n",
    "    xpath = \"/html/body/div[1]/div[3]/div[1]/div/div[2]/div[2]/div[1]/div/div[1]/div/div[3]/div/div[1]/div/div/h1/span[1]/a/span\"\n",
    "    all_result.append(webdriver_crawl(driver, xpath))\n",
    "    \n",
    "    #========== FB帳號 ==========\n",
    "    all_result.append(profile_url)\n",
    "    \n",
    "    #========== IG帳號 ==========\n",
    "    all_result.append(\"?\")\n",
    "    \n",
    "    \n",
    "    #-------------------\n",
    "    #|   他住過的地方   |\n",
    "    #-------------------\n",
    "    driver.get(profile_url+\"&sk=about&section=living&\")\n",
    "    soup = bs4soup(driver)\n",
    "    \n",
    "    #========== 現居城市，家鄉 ==========\n",
    "    current_living, hometown = crawl_country(soup)\n",
    "    all_result.append(current_living)\n",
    "    all_result.append(hometown)\n",
    "    \n",
    "    #========== 地址 ==========\n",
    "    all_result.append(\"?\")\n",
    "    \n",
    "    \n",
    "    #-------------------\n",
    "    #|  學歷與工作經歷  |\n",
    "    #-------------------\n",
    "    driver.get(profile_url+\"&sk=about&section=education&\")\n",
    "    soup = bs4soup(driver)\n",
    "    \n",
    "    #========== 工作、學歷(畢業國中、高中、大學、研究所) ==========\n",
    "    work, education = crawl_work_education(soup)\n",
    "    all_result.append(work)\n",
    "    all_result.append(education)\n",
    "    \n",
    "    \n",
    "    #-------------------\n",
    "    #|  聯絡和基本資料  |\n",
    "    #-------------------\n",
    "    driver.get(profile_url+\"&sk=about&section=contact-info\")\n",
    "    soup = bs4soup(driver)\n",
    "    #========== 性別，血型，性向，語言，宗教，生日 ==========\n",
    "    birthday, gender, blood, sex_orientation, language, religion = crawl_basic_info(soup)\n",
    "    all_result.append(gender)\n",
    "    all_result.append(blood)\n",
    "    all_result.append(sex_orientation)\n",
    "    all_result.append(language)\n",
    "    all_result.append(religion)\n",
    "    all_result.append(birthday)\n",
    "    \n",
    "    #========== 年齡，星座 ==========\n",
    "    age, star_sign = get_age_star(birthday)\n",
    "    all_result.append(age)\n",
    "    all_result.append(star_sign)\n",
    "    \n",
    "    #========== gmail ==========\n",
    "    all_result.append(\"?\")\n",
    "    \n",
    "    #========== 手機號碼 ==========\n",
    "    all_result.append(\"?\")\n",
    "    \n",
    "    #========== 父親名字 ==========\n",
    "    all_result.append(\"?\")\n",
    "    \n",
    "    #========== 母親名字 ==========\n",
    "    all_result.append(\"?\")\n",
    "    \n",
    "\n",
    "    #-------------------\n",
    "    #|  家人和感情狀況  |\n",
    "    #-------------------\n",
    "    driver.get(profile_url+\"&sk=about&section=relationship&\")\n",
    "    soup = bs4soup(driver)\n",
    "    \n",
    "    #========== 感情狀態 ==========\n",
    "    relationship = crawl_relationship(soup)\n",
    "    all_result.append(relationship)\n",
    "    \n",
    "    return all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: Browsing context has been discarded\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1505be713bd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mstart_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"https://www.facebook.com/profile.php?id=100002703513934\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mmy_all_information\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_all_information\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_all_information\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-bf5785cc76fb>\u001b[0m in \u001b[0;36mretrieve_all_information\u001b[1;34m(driver, profile_url)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#-------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_url\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&sk=about&section=living&\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#========== 現居城市，家鄉 ==========\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ac7405216a0a>\u001b[0m in \u001b[0;36mbs4soup\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbs4soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: Browsing context has been discarded\n"
     ]
    }
   ],
   "source": [
    "#token=\"EAALbnTifIKMBADeC06vX50ZA26BiJuHgo6b4IuEQwFFfiKRkaTIx7yIevwf38J3VWZC1Qrh5pvQmeDgQTlZCzgeuUSvelKZAtGdPQY4By7Dh4tb9DonC8mmTYorloyZBHuLl6iwng2fFBxZBh55FDnSEPNL3ArZBOMZCGAKaLJ0ZBahivZBbuXcgBtZAyqlQTbVlOMZD\"\n",
    "token=\"EAAex8H67oRIBANEqewmuYfcvxQsmadG7YZC21p7BJwY20pK1MlyyQLQdgjpYOwe6FnGVrdcXh0hmxZCb4JiWl1XiujcY0Abx4yFzHdw2h5bnsAH8gpWEzIE5FJGo2QmJ7s1XDLZAIHAhS52cePkdwQdM1xUDgRXyhys3gW0nHInejSJIkrwL6HUdtlZAi0fVZC2L4Ji1y7gZDZD\"\n",
    "graph = facebook.GraphAPI(access_token = token)\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "\n",
    "firefox_profile = webdriver.FirefoxProfile()#設定讀圖模式\n",
    "firefox_profile.set_preference('permissions.default.image', 2)#不讀圖片\n",
    "firefox_profile.set_preference('dom.ipc.plugins.enabled.libflashplayer.so', 'false')#不讀圖片，不讀flash driver\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=r'C:\\\\Program Files\\Mozilla Firefox\\geckodriver.exe', options=options,firefox_profile=firefox_profile)\n",
    "LOGIN_URL = 'https://www.facebook.com/login.php?login_attempt=1&lwv=111'\n",
    "\n",
    "driver.get(LOGIN_URL)\n",
    "\n",
    "# wait for the login page to load\n",
    "wait=WebDriverWait(driver, 10)\n",
    "wait.until(ec.visibility_of_element_located((By.ID, \"email\")))\n",
    "\n",
    "driver.find_element_by_id('email').send_keys(facebook_id)\n",
    "driver.find_element_by_id('pass').send_keys(facebook_psw)\n",
    "driver.find_element_by_id('loginbutton').click()\n",
    "\n",
    "start_url = r\"https://www.facebook.com/profile.php?id=100002703513934\"\n",
    "driver.get(start_url)\n",
    "my_all_information = retrieve_all_information(driver, start_url)\n",
    "print(my_all_information)\n",
    "\n",
    "#friends start\n",
    "time.sleep(0.4)\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[1]/div/div[2]/div[2]/div[1]/div/div[1]/div/div[3]/div/div[2]/div[2]/ul/li[3]/a\").click()\n",
    "#$$$This line is a little bit weired, it will crash in some case!!\n",
    "\n",
    "flag=True\n",
    "uls_beforeScroll =len(driver.find_elements_by_xpath(\"//div[@id='pagelet_timeline_app_collection_1155995189:2356318349:2']/ul\"))\n",
    "\n",
    "while(flag):#會抓到社團和粉絲專頁\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(4)\n",
    "    uls_afterScroll = len(driver.find_elements_by_xpath(\"//div[contains(@id,'pagelet_timeline_app_collection_')]/ul\"))\n",
    "    if(uls_afterScroll == uls_beforeScroll):\n",
    "        flag = False\n",
    "    else:\n",
    "        uls_beforeScroll = uls_afterScroll\n",
    "\n",
    "name=\"\"\n",
    "\n",
    "names = driver.find_elements_by_xpath(\"//div[@class='fsl fwb fcb']\")\n",
    "overall_friends_url=[]\n",
    "for name in names:\n",
    "    print(name.find_element_by_tag_name(\"a\").text)\n",
    "    overall_friends_url.append(name.find_element_by_tag_name(\"a\").get_attribute('href'))\n",
    "#friends end\n",
    "\n",
    "all_friends_information=[]\n",
    "for index in range(0,len(overall_friends_url)\n",
    "    driver.get(overall_friends_url[index])\n",
    "    my_all_information=[]\n",
    "    my_all_information=retrieve_all_information(driver,overall_friends_url[index])\n",
    "    all_friends_information.append(my_all_information)\n",
    "    #print(my_all_information)\n",
    "    \n",
    "with open(\"facebook_dataset.csv\",'w',newline='',encoding='utf8') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(['id','中文名字','英文名字','FB URL','ig URL','現居地區','來自地區','地址','工作','學歷','性別','血型','性向','語言','宗教','生日','年齡','星座','gmail','手機號碼','父親名字','母親名字','感情狀態'])\n",
    "    counter=1\n",
    "    current_row=[]\n",
    "    current_row.append(counter)\n",
    "    current_row.extend(my_all_information)\n",
    "    writer.writerow(current_row)\n",
    "    #start the friends\n",
    "    for i in range(0,len(all_friends_information)):\n",
    "        for j in range(0,len(all_friends_information[i])):\n",
    "            all_friends_information[i][j].encode('utf8').decode('utf8')\n",
    "        writer.writerow(all_friends_information[i])\n",
    "        \n",
    "# pickle a variable to a file\n",
    "file = open('all_friends_url.pickle', 'wb')\n",
    "pickle.dump(overall_friends_url, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
